{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from datetime import date\n",
    "import string\n",
    "import unicodedata\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rreplace(s, old, new, n_occurrence):\n",
    "    # Replace the last n_occurrence (n_occurrence = 1 is the last occurrence) of an expression in a string s\n",
    "    li = s.rsplit(old, n_occurrence)\n",
    "    return new.join(li)\n",
    "\n",
    "def str_format(stringg):\n",
    "    \n",
    "    #Elimina simbolos de puntuación, u otros simbolos de un string\n",
    "    \n",
    "    punctuation = list(string.punctuation)          \n",
    "    symbols = ['^','°', 'ª', os.linesep, '\\n']                     \n",
    "    new_string = unicodedata.normalize('NFKD', stringg).encode('ascii', errors='ignore').decode('utf-8') # Elimina tildes \n",
    "\n",
    "    for i in range(len(punctuation)):\n",
    "        new_string = new_string.replace(punctuation[i],'_')   # Elimina simbolos de puntuación\n",
    "    \n",
    "    for i in range(len(symbols)):\n",
    "        new_string = new_string.replace(symbols[i],'')       # Elimina otros simbolos\n",
    "    \n",
    "    new_string = new_string.replace(' ','_').lower()         # Elimina espacios \n",
    "    \n",
    "    while new_string[-1] == '_':\n",
    "        new_string = rreplace(new_string,'_','',1)           # Elimina los \"espacios\" (_) al final del string\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "\n",
    "def read_txt(path, header_int, sep = '|', encoding = 'latin1'):\n",
    "# Lee los archivos txt del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.txt\"))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)] = pd.read_csv(file_path,header=header_int, sep=sep, encoding=encoding, dtype=str)\n",
    "    return d\n",
    "\n",
    "def clean_columns(dict, del_from, col=0):\n",
    "    for keys in dict:\n",
    "        # Elimina la primera y última columna \n",
    "        dict[keys] = dict[keys].drop(columns=dict[keys].columns[0]).\\\n",
    "        drop(columns = dict[keys].columns[-1]).dropna(how = 'all').reset_index(drop = True)\n",
    "        del_from_index = dict[keys].index[dict[keys][dict[keys].columns[col]].str.contains(del_from)].tolist()[0]\n",
    "        \n",
    "        #Elimina filas al final de txt que presentan el resumen del libro de compras/ventas\n",
    "        dict[keys] = dict[keys].iloc[0:del_from_index,:]\n",
    "    return dict\n",
    "\n",
    "def save_as_csv(dict, path, suffixes='', sep=';', encoding = 'latin1'):\n",
    "    \n",
    "    for keys in dict:\n",
    "        dict[keys].to_csv(path + '\\\\' + dt.now().strftime('%Y%m%d') + str(keys) + suffixes + '.csv', sep=sep)\n",
    "        \n",
    "def read_xlsx(path, header_int, sheet_name_str):\n",
    "# Lee los archivos xlsx del path (correspondientes a la fecha de descarga), y crea diccionario con respectivos dataframes\n",
    "    all_files = pd.Series(glob.glob(path + \"/*.xlsx\"))\n",
    "    fecha_str = date.today().strftime(\"%Y%m\")\n",
    "    files = all_files[all_files.astype(str).str.contains(fecha_str)].tolist()\n",
    "    d = {}\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        file_path = files[i]\n",
    "        index_from = file_path.rfind(\"\\\\\") + 1\n",
    "        file_name = str_format(file_path[index_from:-4])\n",
    "        \n",
    "        if file_name[:8].isdigit():\n",
    "            file_name = file_name[9:]\n",
    "        \n",
    "        d[str(file_name)] = pd.read_excel(file_path, header=header_int, sheet_name=sheet_name_str, dtype=str)\n",
    "    return d\n",
    "\n",
    "def col_names_format(dict):\n",
    "    \n",
    "    for keys in dict:\n",
    "        df_col = dict[keys].columns\n",
    "        col_list = []\n",
    "        for col in df_col:\n",
    "            col_list.append(str_format(col))\n",
    "        dict[keys].columns = col_list\n",
    "    \n",
    "    return dict\n",
    "\n",
    "def schema_cols(dict, col_names, empty_col_value = np.nan):\n",
    "    for keys in dict:\n",
    "        for col in col_names:\n",
    "            if col not in dict[keys].columns:\n",
    "                dict[keys][col] = empty_col_value\n",
    "        dict[keys] = dict[keys][col_names]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar limpieza\n",
    "### Leer archivos y guardar en diccionario dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_plan = read_xlsx(r'C:/projects/data_lake/data/input/current/plan_trienal',[4,5], sheet_name_str='Plan trienal 19-21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazar columnas que contengan \"Unnamed\" por \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for keys in dict_plan:\n",
    "    for col in dict_plan[keys].columns:\n",
    "        col_list = list(col)\n",
    "        for name in col_list:\n",
    "            if 'Unnamed' in str(name):\n",
    "                col_list[1] = ''\n",
    "        columns.append(tuple(col_list))\n",
    "    dict_plan[keys].columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificar celdas combinadas en cada df del dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dict_plan:\n",
    "    # Convertir cada elemento de las columnas en string\n",
    "    dict_plan[keys].columns = [tuple(map(str, col)) for col in dict_plan[keys].columns]\n",
    "    \n",
    "    # Unir celdas combinadas\n",
    "    dict_plan[keys].columns = ['_'.join(col) for col in dict_plan[keys].columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar formato de nombre de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_plan = col_names_format(dict_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar en archivos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(dict_plan, r'C:/projects/data_lake/data/output/current/plan_trienal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
